{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKbFy3ewJCJ/PGlnxTgRo3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zakuta/D-QRL/blob/main/Reuploading_PQC_optax_working_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install equinox\n",
        "# !pip install tensorcircuit\n",
        "# !pip install qiskit\n",
        "# !pip install tensorcircuit\n",
        "# !pip install cirq\n",
        "# !pip install openfermion\n",
        "# !pip install gymnax\n",
        "# !pip install brax\n",
        "# !pip install distrax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aiL423KliZM",
        "outputId": "5062a40b-3cee-4f83-c3b5-9cc272a39630"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.10/dist-packages (0.2.25)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (1.25.2)\n",
            "Requirement already satisfied: typeguard<3,>=2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (2.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (4.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "M4PKynPtlaNQ"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from jax import config\n",
        "\n",
        "config.update(\"jax_debug_nans\", True)\n",
        "config.update(\"jax_enable_x64\", True)\n",
        "\n",
        "import jax.numpy as jnp\n",
        "DTYPE=jnp.float64\n",
        "\n",
        "import chex\n",
        "import numpy as np\n",
        "import optax\n",
        "from flax import struct\n",
        "from functools import partial\n",
        "import tensorcircuit as tc\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "import equinox as eqx\n",
        "import types\n",
        "from jaxtyping import Array, PRNGKeyArray\n",
        "from typing import Union, Sequence, List, NamedTuple, Optional, Tuple, Any, Literal, TypeVar\n",
        "import jax.tree_util as jtu\n",
        "from gymnax.environments import environment, spaces\n",
        "from brax import envs\n",
        "from brax.envs.wrappers.training import EpisodeWrapper, AutoResetWrapper\n",
        "\n",
        "K = tc.set_backend(\"jax\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train, x_test = x_train[..., np.newaxis] / 255.0, x_test[..., np.newaxis] / 255.0  # normalize the data\n",
        "\n",
        "def filter(x, y, a, b):\n",
        "    keep = (y == a) | (y == b)\n",
        "    x, y = x[keep], y[keep]\n",
        "    y = y == a\n",
        "    return x, y\n",
        "\n",
        "# Filter out classes 0 and 1\n",
        "x_train, y_train = filter(x_train, y_train, 0, 1)\n",
        "x_test, y_test = filter(x_test, y_test, 0, 1)\n",
        "\n",
        "def apply_pca(X, n_components):\n",
        "    X_flat = np.array([x.flatten() for x in X])\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_pca = pca.fit_transform(X_flat)\n",
        "    return X_pca\n",
        "\n",
        "n_components = 4\n",
        "x_train = apply_pca(x_train, n_components)\n",
        "x_test = apply_pca(x_test, n_components)\n",
        "\n",
        "x_train = jnp.array(x_train, dtype=DTYPE)\n",
        "x_test = jnp.array(x_test, dtype=DTYPE)\n",
        "y_train = jnp.array(y_train, dtype=DTYPE)\n",
        "y_test = jnp.array(y_test, dtype=DTYPE)\n",
        "\n",
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd3z2gCGlch-",
        "outputId": "b82bd89c-5553-4564-fa1f-d3e548ecea1b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PQCLayer(eqx.Module):\n",
        "  theta: Array\n",
        "  lmbd: Array\n",
        "  n_qubits: int = eqx.field(static=True)\n",
        "  n_layers: int = eqx.field(static=True)\n",
        "\n",
        "  def __init__(self, n_qubits: int, n_layers: int, key: PRNGKeyArray):\n",
        "    key = jax.random.PRNGKey(key)\n",
        "    tkey, lkey = jax.random.split(key, num=2)\n",
        "    self.n_qubits = n_qubits\n",
        "    self.n_layers = n_layers\n",
        "    # rotation_params\n",
        "    self.theta = jax.random.uniform(key=tkey, shape=(n_layers + 1, n_qubits, 3),\n",
        "                                    minval=0.0, maxval=np.pi, dtype=DTYPE)\n",
        "    # input encoding params\n",
        "    # self.lmbd = jnp.ones(shape=(n_layers, n_qubits))\n",
        "    self.lmbd = jax.random.uniform(key=lkey, shape=(n_layers, n_qubits),\n",
        "                                    minval=0.0, maxval=np.pi, dtype=DTYPE)\n",
        "\n",
        "    self.params = {'thetas': self.theta, 'lmbds': self.lmbd}\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "  # def __call__(self, X, n_qubits, depth):\n",
        "\n",
        "    # circuit = generate_circuit(self.n_qubits, self.n_layers, self.theta, self.lmbd, inputs)\n",
        "    circuit = tc.Circuit(self.n_qubits)\n",
        "\n",
        "    for l in range(self.n_layers):\n",
        "      # variational part\n",
        "      for qubit_idx in range(self.n_qubits):\n",
        "        circuit.rx(qubit_idx, theta=self.params['thetas'][l, qubit_idx, 0])\n",
        "        circuit.ry(qubit_idx, theta=self.params['thetas'][l, qubit_idx, 1])\n",
        "        circuit.rz(qubit_idx, theta=self.params['thetas'][l, qubit_idx, 2])\n",
        "\n",
        "      # entangling part\n",
        "      for qubit_idx in range(self.n_qubits - 1):\n",
        "        circuit.cnot(qubit_idx, qubit_idx + 1)\n",
        "      if self.n_qubits != 2:\n",
        "        circuit.cnot(self.n_qubits - 1, 0)\n",
        "\n",
        "      # encoding part\n",
        "      for qubit_idx in range(self.n_qubits):\n",
        "        linear_input = inputs[qubit_idx] * self.params['lmbds'][l, qubit_idx]\n",
        "        circuit.rx(qubit_idx, theta=linear_input)\n",
        "\n",
        "    # last variational part\n",
        "    for qubit_idx in range(self.n_qubits):\n",
        "      circuit.rx(qubit_idx, theta=self.params['thetas'][self.n_layers, qubit_idx, 0])\n",
        "      circuit.ry(qubit_idx, theta=self.theta[self.n_layers, qubit_idx, 1])\n",
        "      circuit.rz(qubit_idx, theta=self.theta[self.n_layers, qubit_idx, 2])\n",
        "\n",
        "    return jnp.real(circuit.expectation_ps(z=[0,1,2,3]))"
      ],
      "metadata": {
        "id": "TdokXlyklsi-"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re_uploadingpqc = PQCLayer(n_qubits=4, n_layers=5, key=600)\n",
        "t0 = re_uploadingpqc.theta\n",
        "l0 = re_uploadingpqc.lmbd\n",
        "\n",
        "\n",
        "@eqx.filter_value_and_grad\n",
        "def compute_loss(model, x, y):\n",
        "    pred_y = jax.vmap(model)(x)\n",
        "    loss = jnp.maximum(0, 1 - (2.0 * y - 1.0) * pred_y)\n",
        "    return jnp.mean(loss)\n",
        "\n",
        "# @eqx.filter_jit\n",
        "# def make_step(model, x, y, opt_state):\n",
        "#     loss, grads = compute_loss(model, x, y)\n",
        "#     updates, opt_state = optim.update(grads, opt_state)\n",
        "#     model = eqx.apply_updates(model, updates)\n",
        "#     return loss, model, opt_state\n",
        "\n",
        "# optim = optax.adam(1e-2)\n",
        "# # optim = closure_to_pytree(optim)\n",
        "# opt_state = optim.init(re_uploadingpqc)\n",
        "\n",
        "# steps = 200\n",
        "\n",
        "# for step in range(steps):\n",
        "#   batch_idx = np.random.randint(0, len(x_train), 16)\n",
        "#   x_train_batch = np.array([x_train[i] for i in batch_idx])\n",
        "#   y_train_batch = np.array([y_train[i] for i in batch_idx])\n",
        "#   y_train_batch = np.array([int(value) for value in y_train_batch])\n",
        "\n",
        "#   loss, re_uploadingpqc, opt_state = make_step(re_uploadingpqc, x_train_batch, y_train_batch, opt_state)\n",
        "#   loss = loss.item()\n",
        "#   print(f\"step={step}, loss={loss}\")"
      ],
      "metadata": {
        "id": "t_9UnMZPlvq4"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_loss(re_uploadingpqc, x_train_batch, y_train_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq7dNaV1CiZf",
        "outputId": "48e48496-4e76-42d0-aa79-a0699fd76d1d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array(0.92853316, dtype=float64),\n",
              " PQCLayer(theta=f64[6,4,3], lmbd=f64[5,4], n_qubits=4, n_layers=5))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# has_theta = lambda x: hasattr(x, \"theta\")\n",
        "# where_theta = lambda m: tuple(x.theta for x in jax.tree_leaves(m, is_leaf=has_theta) if has_theta(x))\n",
        "# where_theta(params)\n",
        "\n",
        "# param_spec = eqx.tree_at(where_theta, params, replace_fn=lambda _: \"group2\")\n",
        "\n",
        "# has_lmbd = lambda x: hasattr(x, \"lmbd\")\n",
        "# where_lmbd = lambda m: tuple(x.lmbd for x in jax.tree_leaves(m, is_leaf=has_theta) if has_lmbd(x))\n",
        "# where_lmbd(param_spec)\n",
        "\n",
        "# param_spec = eqx.tree_at(where_lmbd, param_spec, replace_fn=lambda _: \"group1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXwA_JK1n2S5",
        "outputId": "2b52304e-161a-484a-d77a-e46b3d01ac0b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-2fdc672c8ca8>:2: DeprecationWarning: jax.tree_leaves is deprecated: use jax.tree_util.tree_leaves.\n",
            "  where_theta = lambda m: tuple(x.theta for x in jax.tree_leaves(m, is_leaf=has_theta) if has_theta(x))\n",
            "<ipython-input-61-2fdc672c8ca8>:8: DeprecationWarning: jax.tree_leaves is deprecated: use jax.tree_util.tree_leaves.\n",
            "  where_lmbd = lambda m: tuple(x.lmbd for x in jax.tree_leaves(m, is_leaf=has_theta) if has_lmbd(x))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optim = optax.multi_transform({\"group2\": optax.adam(1e-1),\n",
        "#     \"group1\": optax.adam(1e-0),\n",
        "#     },\n",
        "#     param_spec\n",
        "# )"
      ],
      "metadata": {
        "id": "rjB7w75zs7nE"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eqx.filter(re_uploadingpqc, eqx.is_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f23CdX5634Ik",
        "outputId": "b2110aa3-81cf-416f-fc37-7fee8ceda724"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PQCLayer(theta=f64[6,4,3], lmbd=f64[5,4], n_qubits=4, n_layers=5)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QBtbrs4gIR3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXbgusOqISY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The saviour of all the demons!\n",
        "# https://github.com/patrick-kidger/equinox/issues/256\n",
        "class PQCLayer(eqx.Module):\n",
        "  theta: Array\n",
        "  lmbd: Array\n",
        "  n_qubits: int = eqx.field(static=True)\n",
        "  n_layers: int = eqx.field(static=True)\n",
        "\n",
        "  def __init__(self, n_qubits: int, n_layers: int, params):\n",
        "    self.n_qubits = n_qubits\n",
        "    self.n_layers = n_layers\n",
        "    # rotation_params\n",
        "    self.theta = params['thetas']\n",
        "    self.lmbd = params['lmbds']\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    circuit = tc.Circuit(self.n_qubits)\n",
        "\n",
        "    for l in range(self.n_layers):\n",
        "      # variational part\n",
        "      for qubit_idx in range(self.n_qubits):\n",
        "        circuit.rx(qubit_idx, theta=self.theta[l, qubit_idx, 0])\n",
        "        circuit.ry(qubit_idx, theta=self.theta[l, qubit_idx, 1])\n",
        "        circuit.rz(qubit_idx, theta=self.theta[l, qubit_idx, 2])\n",
        "\n",
        "      # entangling part\n",
        "      for qubit_idx in range(self.n_qubits - 1):\n",
        "        circuit.cnot(qubit_idx, qubit_idx + 1)\n",
        "      if self.n_qubits != 2:\n",
        "        circuit.cnot(self.n_qubits - 1, 0)\n",
        "\n",
        "      # encoding part\n",
        "      for qubit_idx in range(self.n_qubits):\n",
        "        linear_input = inputs[qubit_idx] * self.lmbd[l, qubit_idx]\n",
        "        circuit.rx(qubit_idx, theta=linear_input)\n",
        "\n",
        "    # last variational part\n",
        "    for qubit_idx in range(self.n_qubits):\n",
        "      circuit.rx(qubit_idx, theta=self.theta[self.n_layers, qubit_idx, 0])\n",
        "      circuit.ry(qubit_idx, theta=self.theta[self.n_layers, qubit_idx, 1])\n",
        "      circuit.rz(qubit_idx, theta=self.theta[self.n_layers, qubit_idx, 2])\n",
        "\n",
        "    return jnp.real(circuit.expectation_ps(z=[0,1,2,3]))"
      ],
      "metadata": {
        "id": "oylCYPi9IShi"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = 5\n",
        "n_qubits = 4\n",
        "key = 42\n",
        "key = jax.random.PRNGKey(key)\n",
        "tkey, lkey = jax.random.split(key, num=2)\n",
        "params = {'thetas': jax.random.uniform(key=tkey, shape=(n_layers + 1, n_qubits, 3),\n",
        "                                    minval=0.0, maxval=np.pi, dtype=DTYPE),\n",
        "          'lmbds': jnp.ones(shape=(n_layers, n_qubits), dtype=DTYPE)}\n",
        "\n",
        "\n",
        "model = PQCLayer(n_qubits=n_qubits,\n",
        "                 n_layers=n_layers,\n",
        "                 params=params)\n",
        "\n",
        "opt_init, opt_update = optax.adam(0.01)\n",
        "opt_state = opt_init(eqx.filter(model, eqx.is_array))\n",
        "flat_model, treedef_model = jtu.tree_flatten(model)\n",
        "flat_opt_state, treedef_opt_state = jtu.tree_flatten(opt_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfXNLe7FIyct",
        "outputId": "e81ac335-cb6a-478d-cbde-57294eabbab2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2465931498 3679230171] [255383827 267815257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_value_and_grad\n",
        "def compute_loss(model, x, y):\n",
        "    pred_y = jax.vmap(model)(x)\n",
        "    loss = jnp.maximum(0, 1 - (2.0 * y - 1.0) * pred_y)\n",
        "    return jnp.mean(loss)\n",
        "\n",
        "@eqx.filter_jit\n",
        "def make_step(flat_model, flat_opt_state, x, y):\n",
        "    model = jtu.tree_unflatten(treedef_model, flat_model)\n",
        "    opt_state = jtu.tree_unflatten(treedef_opt_state, flat_opt_state)\n",
        "    loss, grads = compute_loss(model, x, y)\n",
        "    updates, opt_state = opt_update(grads, opt_state)\n",
        "    model = eqx.apply_updates(model, updates)\n",
        "    flat_model = jtu.tree_leaves(model)\n",
        "    flat_opt_state = jtu.tree_leaves(opt_state)\n",
        "    return loss, flat_model, flat_opt_state"
      ],
      "metadata": {
        "id": "91JxaNyMLCK-"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_Wk0TrkNB0J",
        "outputId": "6541cfea-6e49-4621-ce01-9d2d00c5e440"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(100):\n",
        "  loss, flat_model, flat_opt_state = make_step(flat_model, flat_opt_state, x_train, y_train)\n",
        "  print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXTx5urzMqkV",
        "outputId": "bfe8eac8-5984-4c37-a471-445f06cd4c41"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9963174666323078\n",
            "0.9857290538749609\n",
            "0.9751737059779213\n",
            "0.9647824093088274\n",
            "0.9547015993555735\n",
            "0.9448562439507416\n",
            "0.935205648239081\n",
            "0.9258598069544338\n",
            "0.9169494841364357\n",
            "0.9085765941426701\n",
            "0.9007932588974266\n",
            "0.8935966540239557\n",
            "0.8869450713482607\n",
            "0.880784429170754\n",
            "0.8750709038856439\n",
            "0.8697800936516723\n",
            "0.8649066040339191\n",
            "0.8604563607789265\n",
            "0.8564367507390658\n",
            "0.8528446979983128\n",
            "0.849653590634601\n",
            "0.8468016393531482\n",
            "0.8441903373571016\n",
            "0.8417000211002499\n",
            "0.8392147946308638\n",
            "0.8366442105739261\n",
            "0.8339308184209852\n",
            "0.8310504618426687\n",
            "0.828005415469505\n",
            "0.824816503001018\n",
            "0.8215147062129982\n",
            "0.8181366654936185\n",
            "0.8147214102472062\n",
            "0.8113072717419417\n",
            "0.8079284209458274\n",
            "0.8046108311032294\n",
            "0.8013690617893784\n",
            "0.7982035903204305\n",
            "0.7951025368397094\n",
            "0.7920460999762872\n",
            "0.7890159481975909\n",
            "0.7860006750016085\n",
            "0.783000384597292\n",
            "0.7800245178242428\n",
            "0.7770877110051126\n",
            "0.7742036987572015\n",
            "0.771378733801539\n",
            "0.7686078784486453\n",
            "0.7658750105492994\n",
            "0.7631551672879043\n",
            "0.7604168338465775\n",
            "0.7576269349031112\n",
            "0.7547511700378333\n",
            "0.7517578736437135\n",
            "0.7486174606512747\n",
            "0.7453041126754057\n",
            "0.741796125223928\n",
            "0.7380743250555436\n",
            "0.7341227025233189\n",
            "0.729928166970242\n",
            "0.7254819264633892\n",
            "0.7207790727970035\n",
            "0.7158212208403274\n",
            "0.710614193849382\n",
            "0.7051714056304723\n",
            "0.6995138016474375\n",
            "0.693672350848797\n",
            "0.6876902495981485\n",
            "0.6816199948498591\n",
            "0.6755212242416844\n",
            "0.6694520612438112\n",
            "0.6634626973051733\n",
            "0.6575903516124235\n",
            "0.6518555091287513\n",
            "0.6462638313668431\n",
            "0.6408096905238538\n",
            "0.6354784895673995\n",
            "0.630256314298041\n",
            "0.6251308383589493\n",
            "0.620097949001938\n",
            "0.6151601277811375\n",
            "0.6103281151733827\n",
            "0.6056199257666691\n",
            "0.6010584434846726\n",
            "0.5966691669398764\n",
            "0.5924705947496501\n",
            "0.5884694609754951\n",
            "0.5846573990608934\n",
            "0.5810127773820423\n",
            "0.5775061996455285\n",
            "0.5741062139119409\n",
            "0.570788290762226\n",
            "0.5675330030754946\n",
            "0.5643243236551061\n",
            "0.5611460312281076\n",
            "0.557977721488433\n",
            "0.5547986203851372\n",
            "0.5515902830012783\n",
            "0.5483401770463678\n",
            "0.5450412922662217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_7pRKkCgMzBN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}