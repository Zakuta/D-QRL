{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJMLMJeVuQ5laH7wyYxvlW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zakuta/D-QRL/blob/main/QRL_try_2_feb23_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1fTvAQcbQBT"
      },
      "outputs": [],
      "source": [
        "# !pip install equinox\n",
        "# !pip install tensorcircuit\n",
        "# !pip install -U qiskit\n",
        "# !pip install tensorcircuit\n",
        "# !pip install cirq\n",
        "# !pip install openfermion\n",
        "# !pip install gymnax\n",
        "# !pip install brax\n",
        "# !pip install distrax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "from jax import config\n",
        "\n",
        "config.update(\"jax_debug_nans\", True)\n",
        "config.update(\"jax_enable_x64\", True)\n",
        "\n",
        "import jax.numpy as jnp\n",
        "DTYPE=jnp.float64\n",
        "\n",
        "import chex\n",
        "import numpy as np\n",
        "import optax\n",
        "from flax import struct\n",
        "from functools import partial\n",
        "import tensorcircuit as tc\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "import equinox as eqx\n",
        "import types\n",
        "from jaxtyping import Array, PRNGKeyArray\n",
        "from typing import Union, Sequence, List, NamedTuple, Optional, Tuple, Any, Literal, TypeVar\n",
        "import jax.tree_util as jtu\n",
        "import gymnax\n",
        "import distrax\n",
        "from gymnax.environments import environment, spaces\n",
        "from brax import envs\n",
        "from brax.envs.wrappers.training import EpisodeWrapper, AutoResetWrapper\n",
        "\n",
        "K = tc.set_backend(\"jax\")"
      ],
      "metadata": {
        "id": "pPpDluwWbm-a"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shamelessly taken from purejaxrl: https://github.com/luchris429/purejaxrl/blob/main/purejaxrl/wrappers.py\n",
        "\n",
        "class GymnaxWrapper(object):\n",
        "    \"\"\"Base class for Gymnax wrappers.\"\"\"\n",
        "\n",
        "    def __init__(self, env):\n",
        "        self._env = env\n",
        "\n",
        "    # provide proxy access to regular attributes of wrapped object\n",
        "    def __getattr__(self, name):\n",
        "        return getattr(self._env, name)\n",
        "\n",
        "\n",
        "class FlattenObservationWrapper(GymnaxWrapper):\n",
        "    \"\"\"Flatten the observations of the environment.\"\"\"\n",
        "\n",
        "    def __init__(self, env: environment.Environment):\n",
        "        super().__init__(env)\n",
        "\n",
        "    def observation_space(self, params) -> spaces.Box:\n",
        "        assert isinstance(\n",
        "            self._env.observation_space(params), spaces.Box\n",
        "        ), \"Only Box spaces are supported for now.\"\n",
        "        return spaces.Box(\n",
        "            low=self._env.observation_space(params).low,\n",
        "            high=self._env.observation_space(params).high,\n",
        "            shape=(np.prod(self._env.observation_space(params).shape),),\n",
        "            dtype=self._env.observation_space(params).dtype,\n",
        "        )\n",
        "\n",
        "    @partial(jax.jit, static_argnums=(0,))\n",
        "    def reset(\n",
        "        self, key: chex.PRNGKey, params: Optional[environment.EnvParams] = None\n",
        "    ) -> Tuple[chex.Array, environment.EnvState]:\n",
        "        obs, state = self._env.reset(key, params)\n",
        "        obs = jnp.reshape(obs, (-1,))\n",
        "        return obs, state\n",
        "\n",
        "    @partial(jax.jit, static_argnums=(0,))\n",
        "    def step(\n",
        "        self,\n",
        "        key: chex.PRNGKey,\n",
        "        state: environment.EnvState,\n",
        "        action: Union[int, float],\n",
        "        params: Optional[environment.EnvParams] = None,\n",
        "    ) -> Tuple[chex.Array, environment.EnvState, float, bool, dict]:\n",
        "        obs, state, reward, done, info = self._env.step(key, state, action, params)\n",
        "        obs = jnp.reshape(obs, (-1,))\n",
        "        return obs, state, reward, done, info\n",
        "\n",
        "\n",
        "@struct.dataclass\n",
        "class LogEnvState:\n",
        "    env_state: environment.EnvState\n",
        "    episode_returns: float\n",
        "    episode_lengths: int\n",
        "    returned_episode_returns: float\n",
        "    returned_episode_lengths: int\n",
        "    timestep: int\n",
        "\n",
        "\n",
        "class LogWrapper(GymnaxWrapper):\n",
        "    \"\"\"Log the episode returns and lengths.\"\"\"\n",
        "\n",
        "    def __init__(self, env: environment.Environment):\n",
        "        super().__init__(env)\n",
        "\n",
        "    @partial(jax.jit, static_argnums=(0,))\n",
        "    def reset(\n",
        "        self, key: chex.PRNGKey, params: Optional[environment.EnvParams] = None\n",
        "    ) -> Tuple[chex.Array, environment.EnvState]:\n",
        "        obs, env_state = self._env.reset(key, params)\n",
        "        state = LogEnvState(env_state, 0, 0, 0, 0, 0)\n",
        "        return obs, state\n",
        "\n",
        "    @partial(jax.jit, static_argnums=(0,))\n",
        "    def step(\n",
        "        self,\n",
        "        key: chex.PRNGKey,\n",
        "        state: environment.EnvState,\n",
        "        action: Union[int, float],\n",
        "        params: Optional[environment.EnvParams] = None,\n",
        "    ) -> Tuple[chex.Array, environment.EnvState, float, bool, dict]:\n",
        "        obs, env_state, reward, done, info = self._env.step(\n",
        "            key, state.env_state, action, params\n",
        "        )\n",
        "        new_episode_return = state.episode_returns + reward\n",
        "        new_episode_length = state.episode_lengths + 1\n",
        "        state = LogEnvState(\n",
        "            env_state=env_state,\n",
        "            episode_returns=new_episode_return * (1 - done),\n",
        "            episode_lengths=new_episode_length * (1 - done),\n",
        "            returned_episode_returns=state.returned_episode_returns * (1 - done)\n",
        "            + new_episode_return * done,\n",
        "            returned_episode_lengths=state.returned_episode_lengths * (1 - done)\n",
        "            + new_episode_length * done,\n",
        "            timestep=state.timestep + 1,\n",
        "        )\n",
        "        info[\"returned_episode_returns\"] = state.returned_episode_returns\n",
        "        info[\"returned_episode_lengths\"] = state.returned_episode_lengths\n",
        "        info[\"timestep\"] = state.timestep\n",
        "        info[\"returned_episode\"] = done\n",
        "        return obs, state, reward, done, info"
      ],
      "metadata": {
        "id": "eEXoWKLccJjF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reuploading_circuit(n_qubits, n_layers, rot_params, input_params, X):\n",
        "  circuit = tc.Circuit(n_qubits)\n",
        "  # params = np.random.normal(size=(n_layers + 1, n_qubits, 3))\n",
        "  # inputs = np.random.normal(size=(n_layers, n_qubits))\n",
        "\n",
        "  for l in range(n_layers):\n",
        "    # variational part\n",
        "    for qubit_idx in range(n_qubits):\n",
        "      circuit.rx(qubit_idx, theta=rot_params[l, qubit_idx, 0])\n",
        "      circuit.ry(qubit_idx, theta=rot_params[l, qubit_idx, 1])\n",
        "      circuit.rz(qubit_idx, theta=rot_params[l, qubit_idx, 2])\n",
        "\n",
        "    # entangling part\n",
        "    for qubit_idx in range(n_qubits - 1):\n",
        "      circuit.cnot(qubit_idx, qubit_idx + 1)\n",
        "    if n_qubits != 2:\n",
        "      circuit.cnot(n_qubits - 1, 0)\n",
        "\n",
        "    # encoding part\n",
        "    for qubit_idx in range(n_qubits):\n",
        "      input = X[qubit_idx] * input_params[l, qubit_idx]\n",
        "      circuit.rx(qubit_idx, theta=input)\n",
        "\n",
        "  # last variational part\n",
        "  for qubit_idx in range(n_qubits):\n",
        "    circuit.rx(qubit_idx, theta=rot_params[n_layers, qubit_idx, 0])\n",
        "    circuit.ry(qubit_idx, theta=rot_params[n_layers, qubit_idx, 1])\n",
        "    circuit.rz(qubit_idx, theta=rot_params[n_layers, qubit_idx, 2])\n",
        "\n",
        "  return circuit\n",
        "\n",
        "\n",
        "class PQCLayer(eqx.Module):\n",
        "  theta: Array\n",
        "  lmbd: Array\n",
        "  n_qubits: int = eqx.field(static=True)\n",
        "  n_layers: int = eqx.field(static=True)\n",
        "\n",
        "  def __init__(self, n_qubits: int, n_layers: int, params: Optional, key: PRNGKeyArray):\n",
        "\n",
        "    key = jax.random.PRNGKey(key)\n",
        "    tkey, lkey = jax.random.split(key, num=2)\n",
        "\n",
        "    if params is None:\n",
        "      self.theta = params['thetas']\n",
        "      self.lmbd = params['lmbds']\n",
        "    else:\n",
        "      self.theta = jax.random.uniform(key=tkey, shape=(n_layers + 1, n_qubits, 3),\n",
        "                                    minval=0.0, maxval=np.pi, dtype=DTYPE)\n",
        "      self.lmbd = jnp.ones(shape=(n_layers, n_qubits), dtype=DTYPE)\n",
        "\n",
        "    self.n_qubits = n_qubits\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    circuit = tc.Circuit(self.n_qubits)\n",
        "\n",
        "    for l in range(self.n_layers):\n",
        "      # variational part\n",
        "      for qubit_idx in range(self.n_qubits):\n",
        "        circuit.rx(qubit_idx, theta=self.theta[l, qubit_idx, 0])\n",
        "        circuit.ry(qubit_idx, theta=self.theta[l, qubit_idx, 1])\n",
        "        circuit.rz(qubit_idx, theta=self.theta[l, qubit_idx, 2])\n",
        "\n",
        "      # entangling part\n",
        "      for qubit_idx in range(self.n_qubits - 1):\n",
        "        circuit.cnot(qubit_idx, qubit_idx + 1)\n",
        "      if self.n_qubits != 2:\n",
        "        circuit.cnot(self.n_qubits - 1, 0)\n",
        "\n",
        "      # encoding part\n",
        "      for qubit_idx in range(self.n_qubits):\n",
        "        linear_input = inputs[qubit_idx] * self.lmbd[l, qubit_idx]\n",
        "        circuit.rx(qubit_idx, theta=linear_input)\n",
        "\n",
        "    # last variational part\n",
        "    for qubit_idx in range(self.n_qubits):\n",
        "      circuit.rx(qubit_idx, theta=self.theta[self.n_layers, qubit_idx, 0])\n",
        "      circuit.ry(qubit_idx, theta=self.theta[self.n_layers, qubit_idx, 1])\n",
        "      circuit.rz(qubit_idx, theta=self.theta[self.n_layers, qubit_idx, 2])\n",
        "\n",
        "    return jnp.real(circuit.expectation_ps(z=jnp.arange(len(self.n_qubits))))\n",
        "\n",
        "\n",
        "# class PQCLayer(eqx.Module):\n",
        "#   theta: jax.Array = eqx.field(converter=jnp.asarray)\n",
        "#   lmbd: jax.Array = eqx.field(converter=jnp.asarray)\n",
        "#   n_qubits: int = eqx.field(static=True)\n",
        "#   n_layers: int = eqx.field(static=True)\n",
        "\n",
        "#   def __init__(self, n_qubits: int, n_layers: int, key: int):\n",
        "#     key = jax.random.PRNGKey(key)\n",
        "#     tkey, lkey = jax.random.split(key, num=2)\n",
        "#     self.n_qubits = n_qubits\n",
        "#     self.n_layers = n_layers\n",
        "#     # rotation_params\n",
        "#     self.theta = jax.random.uniform(key=tkey, shape=(n_layers + 1, n_qubits, 3),\n",
        "#                                     minval=0.0, maxval=np.pi, dtype=DTYPE)\n",
        "#     # input encoding params\n",
        "#     # self.lmbd = jnp.ones(shape=(n_layers, n_qubits))\n",
        "#     self.lmbd = jax.random.uniform(key=lkey, shape=(n_layers, n_qubits),\n",
        "#                                     minval=0.0, maxval=np.pi, dtype=DTYPE)\n",
        "\n",
        "#   def __call__(self, inputs):\n",
        "#   # def __call__(self, X, n_qubits, depth):\n",
        "\n",
        "#     circuit = generate_circuit(self.n_qubits, self.n_layers, self.theta, self.lmbd, inputs)\n",
        "#     # state = circuit.state()\n",
        "#     # return state\n",
        "#     return K.real(circuit.expectation_ps(z=[0,1,2,3]))\n",
        "\n",
        "# class Alternating(eqx.Module):\n",
        "#   w: jax.Array = eqx.field(converter=jnp.asarray)\n",
        "\n",
        "#   def __init__(self, output_dim):\n",
        "#     self.w = jnp.array([[(-1.) ** i for i in range(output_dim)]])\n",
        "\n",
        "#   def __call__(self, inputs):\n",
        "#     return jnp.matmul(inputs, self.w)\n",
        "\n",
        "\n",
        "# class Actor(eqx.Module):\n",
        "#   n_qubits: int\n",
        "#   n_layers: int\n",
        "#   beta: float\n",
        "#   n_actions: Sequence[int]\n",
        "#   key: int\n",
        "\n",
        "#   def __call__(self, x):\n",
        "#     re_uploading_pqc = PQCLayer(n_qubits=self.n_qubits,\n",
        "#                                 n_layers=self.n_layers,\n",
        "#                                 key=self.key)(x)\n",
        "\n",
        "#     process = eqx.nn.Sequential([\n",
        "#         Alternating(self.n_actions),\n",
        "#         eqx.nn.Lambda(lambda x: x * self.beta),\n",
        "#         jax.nn.softmax()\n",
        "#     ])\n",
        "\n",
        "#     policy = process(re_uploading_pqc)\n",
        "\n",
        "#     return policy\n",
        "\n",
        "\n",
        "\n",
        "class QuantumActor(eqx.Module):\n",
        "  theta: jax.Array # trainable\n",
        "  lmbd: jax.Array # trainable\n",
        "  w: jax.Array # trainable\n",
        "  n_qubits: int = eqx.field(static=True)\n",
        "  n_layers: int = eqx.field(static=True)\n",
        "  beta: float = eqx.field(static=True)\n",
        "  n_actions: Sequence[int] = eqx.field(static=True)\n",
        "  # key: int\n",
        "\n",
        "  def __init__(self, n_qubits, n_layers, beta, n_actions, params: Optional, key = 42):\n",
        "\n",
        "    key = jax.random.PRNGKey(key)\n",
        "    key, _key = jax.random.split(key, num=2)\n",
        "\n",
        "    if params is None:\n",
        "      # rotation_params\n",
        "      self.theta = params['thetas']\n",
        "      # input encoding params\n",
        "      self.lmbd = params['lmbds']\n",
        "      # observable weights\n",
        "      self.w = params['ws']\n",
        "    else:\n",
        "      self.theta = jax.random.uniform(key=key, shape=(n_layers + 1, n_qubits, 3),\n",
        "                                    minval=0.0, maxval=np.pi, dtype=DTYPE)\n",
        "      self.lmbd = jnp.ones(shape=(n_layers, n_qubits), dtype=DTYPE)\n",
        "      self.w = jnp.array([[(-1.) ** i for i in range(n_actions)]])\n",
        "\n",
        "\n",
        "    self.n_qubits = n_qubits\n",
        "    self.n_layers = n_layers\n",
        "    self.beta = beta\n",
        "    self.n_actions = n_actions\n",
        "\n",
        "  def quantum_policy_circuit(self, inputs):\n",
        "\n",
        "    # this can be any PQC of the user's choice. hence, I made the decision to make a separate function within this class\n",
        "    circuit = reuploading_circuit(self.n_qubits, self.n_layers, self.theta, self.lmbd, inputs)\n",
        "\n",
        "    return K.real(circuit.expectation_ps(z=np.arange(self.n_qubits)))\n",
        "\n",
        "  def alternating(self, inputs):\n",
        "    return jnp.matmul(inputs, self.w)\n",
        "\n",
        "  def get_params(self):\n",
        "    return {\"theta\": self.theta, \"lmbd\": self.lmbd, \"w\": self.w}\n",
        "\n",
        "  def __call__(self, x):\n",
        "\n",
        "    pqc = self.quantum_policy_circuit(x)\n",
        "    alt = self.alternating(pqc)\n",
        "\n",
        "    # process = eqx.nn.Sequential([\n",
        "    #     alt,\n",
        "    #     eqx.nn.Lambda(lambda x: x * self.beta),\n",
        "    #     jax.nn.softmax()\n",
        "    # ])\n",
        "    # policy = process(pqc)\n",
        "\n",
        "    actor_mean = eqx.nn.Lambda(lambda x: x * self.beta)(alt)\n",
        "    # policy = jax.nn.softmax(actor_mean)\n",
        "    policy = distrax.Softmax(actor_mean)\n",
        "\n",
        "    return policy\n",
        "\n",
        "\n",
        "# class Actor(eqx.Module):\n",
        "#   n_qubits: int\n",
        "#   n_layers: int\n",
        "#   beta: float\n",
        "#   n_actions: Sequence[int]\n",
        "#   pqc: eqx.Module\n",
        "#   alt: eqx.Module\n",
        "#   key: int\n",
        "\n",
        "#   def __init__(self, n_qubits, n_layers, beta, n_actions, key):\n",
        "#     self.n_qubits = n_qubits\n",
        "#     self.n_layers = n_layers\n",
        "#     self.beta = beta\n",
        "#     self.n_actions = n_actions\n",
        "#     self.key = key\n",
        "\n",
        "#     self.pqc = PQCLayer(n_qubits=self.n_qubits,\n",
        "#                         n_layers=self.n_layers,\n",
        "#                         key=self.key)\n",
        "\n",
        "#     self.alt = Alternating(self.n_actions)\n",
        "\n",
        "#   def __call__(self, x):\n",
        "#     re_uploading_pqc = self.pqc(x)\n",
        "\n",
        "#     process = eqx.nn.Sequential([\n",
        "#         self.alt,\n",
        "#         eqx.nn.Lambda(lambda x: x * self.beta),\n",
        "#         jax.nn.softmax()\n",
        "#     ])\n",
        "\n",
        "#     policy = process(re_uploading_pqc)\n",
        "\n",
        "#     return policy\n",
        "\n",
        "\n",
        "class TrainState(eqx.Module):\n",
        "    model: eqx.Module\n",
        "    optimizer: optax.GradientTransformation = eqx.field(static=True)\n",
        "    opt_state: optax.OptState\n",
        "\n",
        "    def __init__(self, model, optimizer, opt_state):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.opt_state = opt_state\n",
        "\n",
        "    def apply_updates_to_model(self, new_params):\n",
        "      # this function is specific and works for this example only. one can think of\n",
        "      # generalizing it to work for updating any given attribute/params of the model.\n",
        "\n",
        "      model_new = eqx.tree_at(where=lambda model: model.theta, pytree=self.model, replace=new_params['thetas'])\n",
        "      model_new = eqx.tree_at(where=lambda model: model.lmbd, pytree=model_new, replace=new_params['lmbds'])\n",
        "      model_new = eqx.tree_at(where=lambda model: model.w, pytree=model_new, replace=new_params['ws'])\n",
        "\n",
        "      return model_new\n",
        "\n",
        "    def apply_gradients(self, params, grads):\n",
        "        grads_dict = {'thetas': grads.theta, 'lmbds': grads.lmbd}\n",
        "        updates, opt_state = self.optimizer.update(grads_dict, self.opt_state, params)\n",
        "        new_params = optax.apply_updates(params, updates)\n",
        "        model_new = self.apply_updates_to_model(new_params)\n",
        "        # model = eqx.apply_updates(self.model, updates)\n",
        "        new_train_state = self.__class__(model=model_new, optimizer=self.optimizer, opt_state=opt_state)\n",
        "        return new_train_state\n",
        "\n",
        "class Transition(NamedTuple):\n",
        "  done: jnp.ndarray\n",
        "  action: jnp.ndarray\n",
        "  reward: jnp.ndarray\n",
        "  log_prob: jnp.ndarray\n",
        "  obs: jnp.ndarray\n",
        "  info: jnp.ndarray"
      ],
      "metadata": {
        "id": "1ZofBx0yccWb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = 5\n",
        "n_qubits = 4\n",
        "beta = 1.0\n",
        "\n",
        "n_envs = 2\n",
        "env, env_params = gymnax.make('CartPole-v1')\n",
        "env = FlattenObservationWrapper(env)\n",
        "env = LogWrapper(env)\n",
        "\n",
        "n_actions = env.action_space(env_params).n\n",
        "\n",
        "rng = 42\n",
        "rng = jax.random.PRNGKey(rng)\n",
        "rng, _rng = jax.random.split(rng)\n",
        "params = {'thetas': jax.random.uniform(key=_rng, shape=(n_layers + 1, n_qubits, 3),\n",
        "                                       minval=0.0, maxval=np.pi, dtype=DTYPE),\n",
        "          'lmbds': jnp.ones(shape=(n_layers, n_qubits), dtype=DTYPE),\n",
        "          'ws': jnp.array([[(-1.) ** i for i in range(n_actions)]], dtype=DTYPE)}\n",
        "\n",
        "actor = QuantumActor(n_qubits=n_qubits, n_layers=n_layers, beta=beta, n_actions=n_actions, params=params)\n",
        "\n",
        "def map_nested_fn(fn):\n",
        "  '''Recursively apply `fn` to the key-value pairs of a nested dict'''\n",
        "  def map_fn(nested_dict):\n",
        "    return {k: (map_fn(v) if isinstance(v, dict) else fn(k, v))\n",
        "            for k, v in nested_dict.items()}\n",
        "  return map_fn\n",
        "\n",
        "label_fn = map_nested_fn(lambda k, _: k)\n",
        "optim = optax.multi_transform({'thetas': optax.amsgrad(0.001),\n",
        "                               'lmbds': optax.amsgrad(0.1),\n",
        "                               'ws': optax.amsgrad(0.1)},\n",
        "                           label_fn)\n",
        "\n",
        "# optim = closure_to_pytree(optim)\n",
        "opt_state = optim.init(params)\n",
        "\n",
        "train_state = TrainState(model=actor, optimizer=optim, opt_state=opt_state)\n",
        "\n",
        "rng, _rng = jax.random.split(rng)\n",
        "reset_rng = jax.random.split(_rng, n_envs)\n",
        "obsv, env_state = jax.vmap(env.reset, in_axes=(0, None))(reset_rng, env_params)\n",
        "\n",
        "def _update_step(runner_state, unused):\n",
        "  # COLLECT TRAJECTORIES\n",
        "  def _env_step(runner_state, ununsed):\n",
        "    train_state, env_state, last_obs, rng = runner_state\n",
        "\n",
        "    rng, _rng = jax.random.split(rng)\n",
        "    policy = actor(last_obs)\n",
        "    action = policy.sample(seed=_rng)\n",
        "    log_prob = policy.log_prob(action)\n",
        "    # action_probs = actor(last_obs)\n",
        "    # action = jax.random.choice(key=_rng, a=n_actions, p=action_probs)\n",
        "\n",
        "    rng, _rng = jax.random.split(rng)\n",
        "    rng_step = jax.random.split(_rng, n_envs)\n",
        "    obs, env_state, reward, done, info = jax.vmap(\n",
        "        env.step, in_axes=(0, 0, 0, None)\n",
        "        )(rng_step, env_state, action, env_params)\n",
        "\n",
        "    transition = Transition(\n",
        "        done, action, reward, log_prob, last_obs, info)\n",
        "\n",
        "    runner_state = (train_state, env_state, obs, rng)\n",
        "\n",
        "    return runner_state, transition\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OiOjp2XJrQZ0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HVhMAzG4sgjS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NqTp5XhMsoMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nP8th2o6xLm7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}